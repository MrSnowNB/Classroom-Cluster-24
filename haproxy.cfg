# HAProxy Configuration for Ollama Load Balancing
# Quad RTX 6000 Ada G8 - 24 Student Classroom Setup
# 4 Ollama instances, one per GPU

global
    log /dev/log    local0
    log /dev/log    local1 notice
    chroot /var/lib/haproxy
    stats socket /run/haproxy/admin.sock mode 660 level admin
    stats timeout 30s
    user haproxy
    group haproxy
    daemon

    # Default SSL material locations
    ca-base /etc/ssl/certs
    crt-base /etc/ssl/private

    # See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
    ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
    ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
    ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
    log     global
    mode    http
    option  httplog
    option  dontlognull
    timeout connect 10s
    timeout client  120s
    timeout server  120s
    errorfile 400 /etc/haproxy/errors/400.http
    errorfile 403 /etc/haproxy/errors/403.http
    errorfile 408 /etc/haproxy/errors/408.http
    errorfile 500 /etc/haproxy/errors/500.http
    errorfile 502 /etc/haproxy/errors/502.http
    errorfile 503 /etc/haproxy/errors/503.http
    errorfile 504 /etc/haproxy/errors/504.http

# Frontend - accepts client connections
frontend ollama_frontend
    bind *:11434
    mode http
    default_backend ollama_backend

    # Log format to track which backend handles each request
    log-format "%ci:%cp [%tr] %ft %b/%s %TR/%Tw/%Tc/%Tr/%Ta %ST %B %CC %CS %tsc %ac/%fc/%bc/%sc/%rc %sq/%bq %hr %hs %{+Q}r"

    # Optional: Add custom headers for debugging
    http-request set-header X-Load-Balancer HAProxy
    http-request set-header X-Request-ID %[uuid()]

# Backend - Ollama instances (one per GPU)
backend ollama_backend
    mode http
    balance roundrobin

    # Health check configuration
    option httpchk GET /
    http-check expect status 200

    # Server timeouts for long-running LLM inference
    timeout server 120s
    timeout connect 10s

    # Ollama instance on GPU 0
    server ollama-gpu0 127.0.0.1:11434 check inter 10s fall 3 rise 2

    # Ollama instance on GPU 1
    server ollama-gpu1 127.0.0.1:11435 check inter 10s fall 3 rise 2

    # Ollama instance on GPU 2
    server ollama-gpu2 127.0.0.1:11436 check inter 10s fall 3 rise 2

    # Ollama instance on GPU 3
    server ollama-gpu3 127.0.0.1:11437 check inter 10s fall 3 rise 2

# Statistics page
listen stats
    bind *:8404
    mode http
    stats enable
    stats uri /stats
    stats refresh 10s
    stats admin if TRUE
    stats show-legends
    stats show-node
